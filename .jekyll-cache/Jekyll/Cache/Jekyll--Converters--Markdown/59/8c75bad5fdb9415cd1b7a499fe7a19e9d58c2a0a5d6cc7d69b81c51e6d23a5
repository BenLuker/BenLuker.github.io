I"r<p class="blurb">
    A friend and I sat down for a weekend and participated in our first ever game jam! Rocket Powered Tin Cans was created for the GMTK Game Jam 2020, the largest online international game jam ever, in a timespan of 48 hours.
    <br /><br />
    Out of 5419 entries, we got 286th place in terms of presentation (top 5%!) and we had a blast doing it.
</p>
<div align="center">
    <iframe class="medium" frameborder="0" src="https://itch.io/embed/694403">
        <a href="https://benluker.itch.io/gmtk-2020">Rocket Powered Tin Cans by Ben Luker, ZaneZukovsky</a>
    </iframe>
</div>
<div class="video-container large">
    <h4 class="caption">Graphics generated by the installation</h4>
    <video controls="" loop="" muted="" poster="../assets/img/work/WISIWYG/GettyGraphics.png">
        <source src="../assets/img/work/WISIWYG/GettyGraphics.webm" type="video/webm" />
    </video>
</div>

<div class="video-container large">
    <h4 class="caption">Interactions with the installation at the Getty Center</h4>
    <video controls="" loop="" muted="" poster="../assets/img/work/WISIWYG/GettyInteraction.png">
        <source src="../assets/img/work/WISIWYG/GettyInteraction.webm" type="video/webm" />
    </video>
</div>

<p>On April 29, 2019, the Getty Center celebrated ‚ÄúColor.‚Äù An event focused on color in imagination, the science of
                                                                    color, art, and the future. The chair of our department, Ana Herruzo, gave us the
                                                                    opportunity to create an immersive, interactive installation merging artificial intelligence and visual arts. Named
                                                                    ‚ÄúWISIWYG:
                                                                    What I See Is What You Get,‚Äù the installation produced live data and animations by analyzing user facial expressions
                                                                    and used a
                                                                    machine learning algorithm to train the artificial neural network models from the Getty Museum‚Äôs art collection. It
                                                                    consisted of three video screens stacked vertically into one seamless display, a camera for facial recognition, and
                                                                    an Xbox kinect for motion data. The experience was powered by TouchDesigner, a tool for creating realtime generative
                                                                    art.</p>

<div class="image-container medium">
    <img src="../assets/img/work/WISIWYG/GettyImage1.jpg" />
</div>

<div class="image-container medium">
    <img src="../assets/img/work/WISIWYG/GettyImage2.jpg" />
</div>

<div class="image-container medium">
    <img src="../assets/img/work/WISIWYG/GettyImage3.png" />
</div>

<div class="image-container medium">
    <img src="../assets/img/work/WISIWYG/GettyImage4.png" />
</div>

<div class="image-container medium">
    <img src="../assets/img/work/WISIWYG/GettyImage5.png" />
</div>

<div class="image-container medium">
    <img src="../assets/img/work/WISIWYG/GettyImage6.jpg" />
</div>

<div class="image-container medium">
    <h4 class="caption">Applied Computer Science students and professors at the Getty Center</h4>
    <img src="../assets/img/work/WISIWYG/GettyGroupPhoto.jpg" />
</div>

<div class="image-container small">
    <h4 class="caption">Art generated by the installation's idle state</h4>
    <img src="../assets/img/work/WISIWYG/GettyIdle.png" />
</div>
:ET